{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PmVQNcQmxvjC"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastaudio.core.all import *\n",
    "from fastaudio.augment.all import *\n",
    "from fastaudio.ci import skip_if_ci\n",
    "import timm\n",
    "from torch.distributions.beta import Beta\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from loguru import logger\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wuI95GINy9Xq"
   },
   "outputs": [],
   "source": [
    "class AudioNormalize(Transform):\n",
    "    \"Normalizes a single `AudioTensor`.\"\n",
    "    def encodes(self, x:AudioTensor): return (x-x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-CzN4gYqzKJ2"
   },
   "outputs": [],
   "source": [
    "def get_x(r): \n",
    "  return path/'genres_original'/r['filename'].split('.')[0]/str(r['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kU8JTuHLD2tv"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "@app.on_event(\"startup\")\n",
    "def load_model():\n",
    "    global model\n",
    "    model = load_learner(Path('D:/Academics/ML Stuff/Genre Predictor/export_r18.pkl'))\n",
    "    return {'message': 'Loaded!'}\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return {'message': 'This is the homepage of the API '}\n",
    "@app.get('/predict')\n",
    "def get_music_category():\n",
    "    Prediction = \"nan\"\n",
    "    Probability = \"nan\"\n",
    "    ResultsArr = []\n",
    "    audio = AudioTensor.create(\"C:/Users/anubh/Downloads/Music/MIDDLE-OF-THE-NIGHT.wav\")\n",
    "    pred,pred_idx,probs = model.predict(audio)\n",
    "    sorted, indices = torch.sort(probs, descending = True)\n",
    "    for i in range(0,5):\n",
    "        Prediction = model.dls.vocab[indices[i]]\n",
    "        Probability = {sorted[i]:.04f}\n",
    "        results = {\n",
    "        \"Prediction\" : \"Prediction\",\n",
    "        \"Probability\" : \"Probability\"\n",
    "        }\n",
    "        ResultsArr.append(results)\n",
    "    return ResultsArr\n",
    "    \n",
    "    \n",
    "#   for i in range(0,5):\n",
    "#     return [{f'Prediction: {model.dls.vocab[indices[i]]}; Probability: {sorted[i]:.04f}'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NgrokTunnel: \"http://e756-2a09-bac0-269-00-681d-1009.ngrok.io\" -> \"http://localhost:8000\">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "\n",
    "ngrok_tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [5916]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51738 - \"GET / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51741 - \"GET /predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51741 - \"GET /predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [5916]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
